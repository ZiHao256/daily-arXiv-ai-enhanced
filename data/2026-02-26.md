<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 11]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Topological Relational Theory: A Simplicial-Complex View of Functional Dependencies, Lossless Decomposition, and Acyclicity](https://arxiv.org/abs/2602.21213)
*Bilge Senturk,Faruk Alpay*

Main category: cs.DB

TL;DR: 本文将函数依赖编码为抽象单纯复形，利用拓扑学工具（Betti数、同调理论）分析和诊断关系数据库模式中的循环依赖结构，并提出了单纯正规形（SNF）概念。


<details>
  <summary>Details</summary>
Motivation: 传统的关系模式设计方法在处理复杂的多属性交互和循环依赖结构时存在不足，需要新的数学工具来深入理解和诊断这些结构，从而指导数据库设计。

Method: 将函数依赖映射为抽象单纯复形的单纯形，定义单纯正规形（SNF）为依赖复形在正维数上的同调无环性（即n≥1时的约化同调消失），利用Mayer-Vietoris序列和神经丛理论重新表述无损连接准则，通过边界矩阵计算Betti数。

Result: 提出了单纯正规形概念；给出了二元无损连接准则的拓扑重述；证明神经丛中的1-循环会阻碍连接树结构；开发了基于Betti数的轻量级模式诊断方法，能够定位"未解释"的依赖循环。

Conclusion: 本研究成功将拓扑学引入关系数据库模式设计中，为理解函数依赖的循环结构提供了新的数学框架，Betti数计算为数据库模式诊断提供了有效的算法工具，弥补了传统FD-chase测试的不足。

Abstract: We develop a topological lens on relational schema design by encoding functional dependencies (FDs) as simplices of an abstract simplicial complex. This dependency complex exposes multi-attribute interactions and enables homological invariants (Betti numbers) to diagnose cyclic dependency structure. We define Simplicial Normal Form (SNF) as homological acyclicity of the dependency complex in positive dimensions, i.e., vanishing reduced homology for all $n \ge 1$. SNF is intentionally weaker than contractibility and does not identify homology with homotopy. For decompositions, we give a topological reformulation of the classical binary lossless-join criterion: assuming dependency preservation, a decomposition is lossless exactly when the intersection attributes form a key for at least one component. Topologically, this yields a strong deformation retraction that trivializes the relevant Mayer--Vietoris boundary map. For multiway decompositions, we show how the nerve of a cover by induced subcomplexes provides a computable certificate: a 1-cycle in the nerve (detected by $H_1$) obstructs join-tree structure and aligns with cyclic join behavior in acyclic-scheme theory. Finally, we discuss an algorithmic consequence: Betti numbers of the dependency complex (or of a decomposition nerve) can be computed from boundary matrices and used as a lightweight schema diagnostic to localize "unexplained" dependency cycles, complementing standard FD-chase tests.

</details>


### [2] [Premature Dimensional Collapse and Tensor-based Execution Paths for High-Dimensional Relational Operations in Cost-Based Database Systems](https://arxiv.org/abs/2602.21237)
*Il-Sun Chang*

Main category: cs.DB

TL;DR: 本文提出了一种基于张量的执行路径，通过延迟过早线性化和保持高维局部性，有效解决了DBMS在内存受限条件下高维关系操作导致的执行不稳定性和尾部延迟放大问题。


<details>
  <summary>Details</summary>
Motivation: 现代基于成本的DBMS在高维关系操作触发哈希表溢出和外部物化等内存状态转换时，频繁出现执行不稳定性和尾部延迟放大。研究识别出一种结构故障模式，即在内存压力下中间表示过早线性化，导致不成比例的I/O放大和类似相变的延迟行为。

Method: 提出张量执行的全新路径，采用延迟物化和结构化中间布局来推迟过早线性化，并保持高维局部性。基于修改的PostgreSQL原型，在受控微基准实验中，通过设置受限内存环境（如work_mem=1MB）进行测试，对比传统执行路径与所提方法。

Result: 在受限内存设置下，传统执行路径会溢出数百兆数据、P99延迟超过数秒，而提出的张量执行路径能够保持稳定执行，将P99延迟降低到亚秒级别。

Conclusion: 表示时序是执行稳定性的第一类设计变量，这补充了传统优化工作中对基数估计和操作符吞吐量的关注。

Abstract: Modern cost-based DBMSs frequently exhibit execution instability and tail-latency amplification when high-dimensional relational operations trigger memory-regime transitions such as hash-table spilling and external materialization. We identify a structural failure mode in which intermediate representations are prematurely linearized under memory pressure, causing disproportionate I/O amplification and phase-transition-like latency behavior. To mitigate this, we propose a tensor-based execution path that delays premature linearization and preserves higher-dimensional locality through late materialization and structured intermediate layouts. Using a modified PostgreSQL-based prototype and controlled microbenchmarks, we show that under constrained memory settings (e.g., work_mem=1MB) conventional execution can spill hundreds of megabytes and exceed multi-second P99 latency, while the proposed path maintains stable execution and reduces P99 latency to sub-second levels. Our results suggest that representation timing is a first-class design variable for execution stability, complementing traditional optimization efforts focused on cardinality estimation and operator throughput.

</details>


### [3] [PiPNN: Ultra-Scalable Graph-Based Nearest Neighbor Indexing](https://arxiv.org/abs/2602.21247)
*Tobias Rubel,Richard Wen,Laxman Dhulipala,Lars Gottesbüren,Rajesh Jayaram,Jakub Łącki*

Main category: cs.DB

TL;DR: PiPNN是一种快速构建近似最近邻索引的新算法，通过在线剪枝方法HashPrune避免了现有图方法中的搜索瓶颈，在单台多核机上20分钟内构建10亿级数据集的高质量索引。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的ANN索引算法（如HNSW和Vamana/DiskANN）虽然查询性能优秀，但构建时间都非常长，主要瓶颈在于依赖大量随机访问的beam搜索操作，导致无法高效处理大规模数据集。

Method: 提出PiPNN算法及其核心创新HashPrune，一种新型的在线剪枝算法，能够动态维护稀疏边集合；HashPrune允许将数据集划分为重叠子问题，利用密集矩阵乘法内核高效执行批量距离计算，并将边子集动态流入HashPrune；HashPrune确保构建过程中内存有界，无需额外中间内存即可构建高质量索引。

Result: PiPNN在构建速度上显著超越现有方法：比Vamana快11.6倍，比HNSW快12.9倍，比MIRAGE快19.1倍，比FastKCNA快17.3倍；生成的索引具有更高的查询吞吐量；首次在单台多核机器上在20分钟内构建10亿规模数据集的高质量ANN索引。

Conclusion: PiPNN通过HashPrune成功突破现有图构建方法的搜索瓶颈，在保持优异查询性能的同时大幅提升构建效率，为大规模ANN索引的实时构建提供了实际可行的解决方案。

Abstract: The fastest indexes for Approximate Nearest Neighbor Search today are also the slowest to build: graph-based methods like HNSW and Vamana achieve state-of-the-art query performance but have large construction times due to relying on random-access-heavy beam searches. We introduce PiPNN (Pick-in-Partitions Nearest Neighbors), an ultra-scalable graph construction algorithm that avoids this ``search bottleneck'' that existing graph-based methods suffer from.
  PiPNN's core innovation is HashPrune, a novel online pruning algorithm which dynamically maintains sparse collections of edges. HashPrune enables PiPNN to partition the dataset into overlapping sub-problems, efficiently perform bulk distance comparisons via dense matrix multiplication kernels, and stream a subset of the edges into HashPrune. HashPrune guarantees bounded memory during index construction which permits PiPNN to build higher quality indices without the use of extra intermediate memory.
  PiPNN builds state-of-the-art indexes up to 11.6x faster than Vamana (DiskANN) and up to 12.9x faster than HNSW. PiPNN is significantly more scalable than recent algorithms for fast graph construction. PiPNN builds indexes at least 19.1x faster than MIRAGE and 17.3x than FastKCNA while producing indexes that achieve higher query throughput. PiPNN enables us to build, for the first time, high-quality ANN indexes on billion-scale datasets in under 20 minutes using a single multicore machine.

</details>


### [4] [BuffCut: Prioritized Buffered Streaming Graph Partitioning](https://arxiv.org/abs/2602.21248)
*Linus Baumgärtner,Adil Chhabra,Marcelo Fonseca Faraj,Christian Schulz*

Main category: cs.DB

TL;DR: BuffCut是通过优先级缓冲与批量多级分配相结合的缓冲流式图分区方法，显著降低了边割量并提升了分割效率和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 传统流式图分区器单次分配启发式对流顺序高度敏感，特别是在对抗性流顺序下，易产生显著高于内存方法的边割，亟需提升分区质量与可扩展性。

Method: BuffCut维护有界优先级缓冲区，延迟决策不足的节点分配并调节考虑顺序；通过迭代选择优先级最高的节点增量构建高局部性批次，并利用多级分区算法对批次进行分配。

Result: 在多个真实世界和合成图实验中，相比最强优先级缓冲基线减少20.8%边割，速度提升2.9倍、内存节省11.3倍；相比次优缓冲方法降低15.8%边割，仅带来1.8倍运行时间和1.09倍内存的开销。

Conclusion: 通过优先级缓冲与批量多级分配的创新结合，BuffCut有效恢复了流中的局部性结构，在大幅提升流式图分区质量的同时保持了高效计算和低内存消耗。

Abstract: Streaming graph partitioners enable resource-efficient and massively scalable partitioning, but one-pass assignment heuristics are highly sensitive to stream order and often yield substantially higher edge cuts than in-memory methods. We present BuffCut, a buffered streaming partitioner that narrows this quality gap, particularly when stream ordering is adversarial, by combining prioritized buffering with batch-wise multilevel assignment. BuffCut maintains a bounded priority buffer to delay poorly informed decisions and regulate the order in which nodes are considered for assignment. It incrementally constructs high-locality batches of configurable size by iteratively inserting the highest-priority nodes from the buffer into the batch, effectively recovering locality structure from the stream. Each batch is then assigned via a multilevel partitioning algorithm. Experiments on diverse real-world and synthetic graphs show that BuffCut consistently outperforms state-of-the-art buffered streaming methods. Compared to the strongest prioritized buffering baseline, BuffCut achieves 20.8% fewer edge cuts while running 2.9 times faster and using 11.3 times less memory. Against the next-best buffered method, it reduces edge cut by 15.8% with only modest overheads of 1.8 times runtime and 1.09 times memory.

</details>


### [5] [Quality of Descriptive Information on Cultural Heritage Objects: Definition and Empirical Evaluation](https://arxiv.org/abs/2602.21249)
*Markus Matoni,Arno Kesper,Gabriele Taentzer*

Main category: cs.DB

TL;DR: 本研究提出了一个针对文化遗产对象描述性信息的数据质量维度定义，并通过现实世界数据质量问题进行了实证验证，最终建立了该领域综合的数据质量定义。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏广泛认可的、领域无关的数据质量定义共识；现有框架主要针对特定领域、数据类型或使用情境定制；尽管电子健康记录数据和链接数据等领域已有质量评估框架，但文化遗产对象的描述性信息质量评估方法仍不完善；现有质量定义多为理论性，缺乏基于现实世界数据问题的实证验证。

Method: 1) 通过对现有质量维度的深入分析，定义了一套专门用于捕捉文化遗产对象描述性信息特征的质量维度，并通过领域特定示例进行说明；2) 使用来自文化遗产领域的精心策划的现实世界数据质量问题集，对所提出的质量定义进行实用性评估。

Result: 经验评估验证了论文提出的数据质量定义的有效性，最终得出了文化遗产领域全面的数据质量定义。该定义能够有效地捕捉和处理该领域中实际存在的数据质量问题。

Conclusion: 本研究成功填补了文化遗产数据质量定义的空白，提出了经过实证验证的、适用于文化遗产对象描述性信息的质量维度和综合定义，为该领域的数据质量评估提供了理论基础和实践指导。

Abstract: Effective data processing depends on the quality of the underlying data. However, quality issues such as inconsistencies and uncertainties, can significantly impede the processing and subsequent use of data. Despite the centrality of data quality to a wide range of computational tasks, there is currently no broadly accepted, domain-independent consensus on the definition of data quality. Existing frameworks primarily define data quality in ways that are tailored to specific domains, data types, or contexts of use. Although quality assessment frameworks exist for specific domains, such as electronic health record data and linked data, corresponding approaches for descriptive information about cultural heritage objects remain underdeveloped. Moreover, existing quality definitions are often theoretical in nature and lack empirical validation based on real-world data problems. In this paper, we address these limitations by first defining a set of quality dimensions specifically designed to capture the characteristics of descriptive information about cultural heritage objects. Our definition is based on an in-depth analysis of existing dimensions and is illustrated through domain-specific examples. We then evaluate the practical applicability of our proposed quality definition using a curated set of real-world data quality problems from the cultural heritage domain. This empirical evaluation substantiates our definition of data quality, resulting in a comprehensive definition of data quality in this domain.

</details>


### [6] [Both Ends Count! Just How Good are LLM Agents at "Text-to-Big SQL"?](https://arxiv.org/abs/2602.21480)
*Germán T. Eizaguirre,Lars Tissen,Marc Sánchez-Artigas*

Main category: cs.DB

TL;DR: 论文提出了"Text-to-Big SQL"评估框架，针对Text-to-SQL系统在大数据场景下的评估缺失问题，引入新指标来评估执行效率、成本和数据规模影响，通过生产级LLM agents的广泛评估证明了这些指标的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL基准在小数据集上评估，但现实中Text-to-SQL系统常嵌入到Big Data工作流中；小数据集上微小的翻译错误在大规模数据下会导致巨大成本和延迟开销，这是现有Text-to-SQL指标完全忽视的问题。

Method: 引入新颖的代表性评估指标；专注于生产级LLM agents（数据库无关系统）；通过对前沿模型的广泛评估进行比较研究；提供延迟和成本的细粒度、跨模型比较分析。

Result: 研究表明传统Text-to-SQL指标不足以评估Big Data场景；提出的Text-to-Big SQL指标能够准确反映执行效率、成本以及数据规模的影响；获得了LLM特定见解和模型间的性能比较。

Conclusion: Text-to-SQL系统需要针对Big Data场景开发专门的评估框架，传统评估方法在大规模数据场景下失效；新的Text-to-Big SQL指标为实际生产环境中的评估提供了更准确和实用的工具。

Abstract: Text-to-SQL and Big Data are both extensively benchmarked fields, yet there is limited research that evaluates them jointly. In the real world, Text-to-SQL systems are often embedded with Big Data workflows, such as large-scale data processing or interactive data analytics. We refer to this as "Text-to-Big SQL". However, existing text-to-SQL benchmarks remain narrowly scoped and overlook the cost and performance implications that arise at scale. For instance, translation errors that are minor on small datasets lead to substantial cost and latency overheads as data scales, a relevant issue completely ignored by text-to-SQL metrics.
  In this paper, we overcome this overlooked challenge by introducing novel and representative metrics for evaluating Text-to-Big SQL. Our study focuses on production-level LLM agents, a database-agnostic system adaptable to diverse user needs. Via an extensive evaluation of frontier models, we show that text-to-SQL metrics are insufficient for Big Data. In contrast, our proposed text-to-Big SQL metrics accurately reflect execution efficiency, cost, and the impact of data scale. Furthermore, we provide LLM-specific insights, including fine-grained, cross-model comparisons of latency and cost.

</details>


### [7] [I/O Optimizations for Graph-Based Disk-Resident Approximate Nearest Neighbor Search: A Design Space Exploration](https://arxiv.org/abs/2602.21514)
*Liang Li,Shufeng Gong,Yanan Yang,Yiduo Wang,Jie Wu*

Main category: cs.DB

TL;DR: 提出面向I/O优化的磁盘ANN框架OctopusANN，通过系统性地组合内存布局、磁盘布局和搜索算法三个维度的技术，在匹配Recall@10=90%时，比Starling提升4.1-37.9%吞吐量，比DiskANN提升87.5-149.5%吞吐量。


<details>
  <summary>Details</summary>
Motivation: SSD上的近似最近邻搜索日益受I/O瓶颈限制（I/O占查询延迟的70-90%），传统的孤立优化方法难以有效突破I/O限制，需要从系统角度通过多维度协同来改善磁盘ANN的I/O效率。

Method: 1) 提出I/O优先框架，从内存布局、磁盘布局和搜索算法三个维度组织技术；2) 引入页级复杂度模型，解释页局部性和路径长度如何共同决定页读取；3) 在四个公共数据集上使用一致实现进行系统量化；4) 构建OctopusANN系统，组合了内存驻留导航、动态宽度、页混洗和页搜索等技术。

Result: 实验发现：内存驻留导航和动态宽度提供最强的独立增益；页混洗和页搜索单独较弱但互补；OctopusANN在匹配Recall@10=90%时，相比Starling提升4.1-37.9%吞吐量，相比DiskANN提升87.5-149.5%吞吐量，显著减少I/O开销。

Conclusion: 提炼了针对不同并发级别和精度约束的可操作设计指南，强调在推进磁盘ANN性能前沿时应采用系统性方法组合多维度技术，而非孤立地进行局部优化。

Abstract: Approximate nearest neighbor (ANN) search on SSD-backed indexes is increasingly I/O-bound (I/O accounts for 70--90\% of query latency). We present an I/O-first framework for disk-based ANN that organizes techniques along three dimensions: memory layout, disk layout, and search algorithm. We introduce a page-level complexity model that explains how page locality and path length jointly determine page reads, and we validate the model empirically. Using consistent implementations across four public datasets, we quantify both single-factor effects and cross-dimensional synergies. We find that (i) memory-resident navigation and dynamic width provide the strongest standalone gains; (ii) page shuffle and page search are weak alone but complementary together; and (iii) a principled composition, OctopusANN, substantially reduces I/O and achieves 4.1--37.9\% higher throughput than the state-of-the-art system Starling and 87.5--149.5\% higher throughput than DiskANN at matched Recall@10=90\%. Finally, we distill actionable guidelines for selecting storage-centric or hybrid designs across diverse concurrency levels and accuracy constraints, advocating systematic composition rather than isolated tweaks when pushing the performance frontier of disk-based ANN.

</details>


### [8] [RAC: Relation-Aware Cache Replacement for Large Language Models](https://arxiv.org/abs/2602.21547)
*Yuchong Wu,Zihuan Xu,Wangze Ni,Peng Cheng,Lei Chen,Xuemin Lin,Heng Tao Shen,Kui Ren*

Main category: cs.DB

TL;DR: 提出了一种基于语义关系的缓存替换策略RAC，通过主题流行度和结构重要性两个信号，在有限的缓存容量下显著提升LLM服务的缓存命中率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型服务的扩展面临成本和延迟挑战，需要在紧缩容量下实现高效缓存。现有的缓存替换策略（从启发式方法到基于学习的方法）主要依赖有限的统计窗口（如最近访问和访问频率），这些信号在具有长重用距离和稀疏局部重复特征的现实世界LLM工作负载中不够鲁棒。

Method: 提出关系感知缓存(RAC)，一种利用请求间语义关系指导驱逐决策的在线驱逐策略。RAC综合两个关系感知信号：(1)主题流行度-在主题层面聚合访问证据以捕获长期重用；(2)结构重要性-利用局部主题内依赖结构来区分条目的未来重用价值。

Result: 在多种工作负载上的广泛评估表明，RAC始终保持高效，在缓存命中率方面持续超过现有最先进基线20%-30%。

Conclusion: 通过关注语义关系而非仅依赖局部统计特征，RAC有效解决了传统缓存方法在LLM场景下的局限性，为现实世界的大语言模型服务提供了一种高效的缓存解决方案。

Abstract: The scaling of Large Language Model (LLM) services faces significant cost and latency challenges, making effective caching under tight capacity crucial. Existing cache replacement policies, from heuristics to learning-based methods, predominantly rely on limited-window statistics such as recency and frequency. We show these signals are not robust for real-world LLM workloads, which exhibit long reuse distances and sparse local recurrence.
  To address these limitations, we propose Relation-Aware Cache (RAC), an online eviction strategy that leverages semantic relations among requests to guide eviction decisions. RAC synthesizes two relation-aware signals: (1) Topical Prevalence, which aggregates access evidence at the topic level to capture long-horizon reuse; and (2) Structural Importance, which leverages local intra-topic dependency structure to discriminate entries by their future reuse value. Extensive evaluations show that RAC maintains high effectiveness across diverse workloads, consistently surpassing state-of-the-art baselines by 20%--30% in cache hit ratio.

</details>


### [9] [Epoch-based Optimistic Concurrency Control in Geo-replicated Databases](https://arxiv.org/abs/2602.21566)
*Yunhao Mao,Harunari Takata,Michail Bachras,Yuqiu Zhang,Shiquan Zhang,Gengrui Zhang,Hans-Arno Jacobsen*

Main category: cs.DB

TL;DR: Minerva是一种支持高可扩展多主复制的统一分布式并发控制系统，通过基于epoch的异步复制协议、乐观并发控制和确定性重执行机制，在保证串行化的同时显著提升了地理复制数据库的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 地理分布对现代在线应用的可靠性和高可用性至关重要，但在地理复制数据库中支持高性能可串行化事务仍面临重大挑战。主要困难在于分布式原子提交、并发控制和容错复制协议在网络高延迟环境下存在大量的过度协调问题。

Method: 1. 介绍了Minerva，这是一个为高可扩展多主复制设计的统一分布式并发控制；2. 采用基于epoch的异步复制协议，将数据传播与提交过程解耦，实现持续事务复制；3. 使用乐观并发控制，允许任意副本并发执行事务并无协调提交；4. 检测到冲突时不中止事务，而是通过确定性重执行解决冲突，确保串行化且不牺牲性能；5. 构建冲突图并使用最大权重独立集算法选择最优事务子集进行提交，最小化重执行事务数量。

Result: 评估结果表明，Minerva显著优于最先进的复制数据库：在可扩展性实验中吞吐量提升超过3倍，在使用TPC-C基准的高网络延迟模拟中吞吐量提升2.8倍。

Conclusion: Minerva通过创新的epoch异步复制、乐观并发控制、确定性重执行和基于冲突图的事务选择机制，成功解决了地理分布式数据库在高网络延迟环境下的过度协调问题，在保证可串行化隔离级别的同时实现了性能的显著提升。

Abstract: Geo-distribution is essential for modern online applications to ensure service reliability and high availability. However, supporting high-performance serializable transactions in geo-replicated databases remains a significant challenge. This difficulty stems from the extensive over-coordination inherent in distributed atomic commitment, concurrency control, and fault-tolerance replication protocols under high network latency.
  To address these challenges, we introduce Minerva, a unified distributed concurrency control designed for highly scalable multi-leader replication. Minerva employs a novel epoch-based asynchronous replication protocol that decouples data propagation from the commitment process, enabling continuous transaction replication. Optimistic concurrency control is used to allow any replicas to execute transactions concurrently and commit without coordination. In stead of aborting transactions when conflicts are detected, Minerva uses deterministic re-execution to resolve conflicts, ensuring serializability without sacrificing performance. To further enhance concurrency, we construct a conflict graph and use a maximum weight independent set algorithm to select the optimal subset of transactions for commitment, minimizing the number of re-executed transactions. Our evaluation demonstrates that Minerva significantly outperforms state-of-the-art replicated databases, achieving over $3\times$ higher throughput in scalability experiments and $2.8\times$ higher throughput during a high network latency simulation with the TPC-C benchmark.

</details>


### [10] [Towards Autonomous Graph Data Analytics with Analytics-Augmented Generation](https://arxiv.org/abs/2602.21604)
*Qiange Wang,Chaoyi Chen,Jingqi Gao,Zihan Wang,Yanfeng Zhang,Ge Yu*

Main category: cs.DB

TL;DR: 本文提出了“分析增强生成”新范式，通过将LLM定位为知识驱动的分析协调器，实现从自然语言意图到自动化端到端图数据分析的完整流程。


<details>
  <summary>Details</summary>
Motivation: 单纯的检索或代码生成型LLM代理无法实现可靠的端到端图数据分析。虽然LLM具备强大推理能力，但非专业用户的实际图数据分析需要明确的分析基础来支撑意图-执行转换、任务感知图构建以及跨多样化图算法的可靠执行。

Method: 提出AAG范式，将分析计算视为一等公民，并通过三个核心组件实现：1）知识驱动的任务规划 2）以算法为中心的LLM-分析交互 3）任务感知的图构建

Result: AAG构建了端到端的图数据分析管道，能够将用户的自然语言意图自动转化为可执行的流程并输出可解释的结果。

Conclusion: AAG范式通过将LLM作为知识驱动的分析协调器并与专业计算能力深度耦合，为非专业用户提供了一种既强大又可靠、可解释的图数据分析新框架。

Abstract: This paper argues that reliable end-to-end graph data analytics cannot be achieved by retrieval- or code-generation-centric LLM agents alone. Although large language models (LLMs) provide strong reasoning capabilities, practical graph analytics for non-expert users requires explicit analytical grounding to support intent-to-execution translation, task-aware graph construction, and reliable execution across diverse graph algorithms. We envision Analytics-Augmented Generation (AAG) as a new paradigm that treats analytical computation as a first-class concern and positions LLMs as knowledge-grounded analytical coordinators. By integrating knowledge-driven task planning, algorithm-centric LLM-analytics interaction, and task-aware graph construction, AAG enables end-to-end graph analytics pipelines that translate natural-language user intent into automated execution and interpretable results.

</details>


### [11] [RAMSeS: Robust and Adaptive Model Selection for Time-Series Anomaly Detection Algorithms](https://arxiv.org/abs/2602.21766)
*Mohamed Abdelmaksoud,Sheng Ding,Andrey Morozov,Ziawasch Abedjan*

Main category: cs.DB

TL;DR: 本文提出RAMSeS框架，通过结合遗传算法优化的堆叠集成和自适应模型选择两条分支，实现跨域时序异常检测，在F1指标上超越先有方法。


<details>
  <summary>Details</summary>
Motivation: 时序数据在不同领域差异巨大，异常的定义具有上下文依赖性。现有方法在特定数据集上表现良好但难以迁移，核心挑战在于设计一种方法既能在特定情境下表现优异，又能适应不同数据复杂度的跨域场景。

Method: 提出RAMSeS（时序异常检测的鲁棒自适应模型选择）框架，包含两个分支：(i)使用遗传算法优化的堆叠集成，利用互补检测器的优势；(ii)自适应模型选择分支，通过Thompson采样、基于GAN的鲁棒性测试和蒙特卡洛模拟来识别最优的单检测器。

Result: 该双策略方法充分利用多模型的集体优势，并能适应数据集特定特征，在F1指标上表现优于先有方法。

Conclusion: RAMSeS通过集成学习和自适应模型选择的结合，有效解决了异常检测的领域特异性问题，实现了在多种复杂场景下的优异性能。

Abstract: Time-series data vary widely across domains, making a universal anomaly detector impractical. Methods that perform well on one dataset often fail to transfer because what counts as an anomaly is context dependent. The key challenge is to design a method that performs well in specific contexts while remaining adaptable across domains with varying data complexities. We present the Robust and Adaptive Model Selection for Time-Series Anomaly Detection RAMSeS framework. RAMSeS comprises two branches: (i) a stacking ensemble optimized with a genetic algorithm to leverage complementary detectors. (ii) An adaptive model-selection branch identifies the best single detector using techniques including Thompson sampling, robustness testing with generative adversarial networks, and Monte Carlo simulations. This dual strategy exploits the collective strength of multiple models and adapts to dataset-specific characteristics. We evaluate RAMSeS and show that it outperforms prior methods on F1.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning](https://arxiv.org/abs/2602.21534)
*Xiaoxuan Wang,Han Zhang,Haixin Wang,Yidan Shi,Ruoyan Li,Kaiqiao Han,Chenyi Tong,Haoran Deng,Renliang Sun,Alexander Taylor,Yanqiao Zhu,Jason Cong,Yizhou Sun,Wei Wang*

Main category: cs.AI

TL;DR: 本文提出了ARLArena分析框架和SAMPO优化方法，解决主体强化学习（ARL）训练不稳定问题。


<details>
  <summary>Details</summary>
Motivation: ARL在训练复杂多步交互任务时存在高度不稳定性，经常导致训练崩溃；这种不稳定性限制了其可扩展性和对算法设计选择的系统探索。

Method: 提出ARLArena框架，构建标准化测试平台，将策略梯度分解为四个核心设计维度进行细粒度分析；在此基础上设计SAMPO方法，通过统一的策略梯度视角，针对ARL中不稳定性的主要来源进行优化。

Result: SAMPO在多种主体任务上实现了持续稳定的训练效果，并展现出强大的性能表现。

Conclusion: 为ARL领域提供了统一的策略梯度理论视角，并为构建稳定可重现的基于大语言模型的主体训练流程提供了实践指导。

Abstract: Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limits scalability to larger environments and longer interaction horizons, and constrains systematic exploration of algorithmic design choices. In this paper, we first propose ARLArena, a stable training recipe and systematic analysis framework that examines training stability in a controlled and reproducible setting. ARLArena first constructs a clean and standardized testbed. Then, we decompose policy gradient into four core design dimensions and assess the performance and stability of each dimension. Through this fine-grained analysis, we distill a unified perspective on ARL and propose SAMPO, a stable agentic policy optimization method designed to mitigate the dominant sources of instability in ARL. Empirically, SAMPO achieves consistently stable training and strong performance across diverse agentic tasks. Overall, this study provides a unifying policy gradient perspective for ARL and offers practical guidance for building stable and reproducible LLM-based agent training pipelines.

</details>
